{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cd1afad-8b6d-4803-a0fa-93f2275f1655",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "### Dataset Origin\n",
    "The dataset contains real-world information from Brazilian e-commerce transactions. It was originally made publicly available by *Olist*, a Brazilian online retail platform, for educational and analytical purposes. The data is anonymized and reflects actual customer orders, payments, products, and reviews.\n",
    "\n",
    "### Objective\n",
    "The main goal of this project is to build an interpretable model to support the Business Intelligence team by explaining the key factors behind positive or negative customer reviews.  \n",
    "This model is designed for **explainability**, not for **predictive accuracy**. Its purpose is to clearly identify which variables have the greatest influence on customer satisfaction, helping prioritize service improvements. The business goal is not to predict but to address and resolve negative customer experiences.\n",
    "The project is intended to be used and reviewed within a Jupyter Notebook environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed3096e-778a-4f4e-877e-27ecfad59e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11fc627d-e25f-40ef-a6ef-b5ff1b4bbe9f",
   "metadata": {},
   "source": [
    "### EDA \n",
    "**This section can be skiped**. No necessary code to execute model is on this secction. If dessired jump to Conclussions. This secction is a small sample to ejemplify the code used to explore de data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35d8626e-2736-4957-9b3a-ea1e78ce2680",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data upload\n",
    "import pandas as pd\n",
    "\n",
    "data_path = \"../Data/\"\n",
    "\n",
    "df_customers = pd.read_csv(data_path + \"olist_customers_dataset.csv\")\n",
    "df_geolocation = pd.read_csv(data_path + \"olist_geolocation_dataset.csv\")\n",
    "df_order_items = pd.read_csv(data_path + \"olist_order_items_dataset.csv\")\n",
    "df_payments = pd.read_csv(data_path + \"olist_order_payments_dataset.csv\")\n",
    "df_reviews = pd.read_csv(data_path + \"olist_order_reviews_dataset.csv\")\n",
    "df_orders = pd.read_csv(data_path + \"olist_orders_dataset.csv\")\n",
    "df_products = pd.read_csv(data_path + \"olist_products_dataset.csv\")\n",
    "df_sellers = pd.read_csv(data_path + \"olist_sellers_dataset.csv\")\n",
    "df_category = pd.read_csv(data_path + \"product_category_name_translation.csv\")\n",
    "\n",
    "df_closed = pd.read_csv(data_path + \"olist_closed_deals_dataset.csv\")\n",
    "df_leads = pd.read_csv(data_path + \"olist_marketing_qualified_leads_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff3840b-a845-4a6f-8add-8d642c6ecf06",
   "metadata": {},
   "source": [
    "Full data has 3 kind of columns, dates, numeric and text.\n",
    "<!--  -->\n",
    "Next is a sample of resources used for all data and evaluation process for each column kind. This was repeated for all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0392560-fbc0-44d1-b4db-0a12a64fd7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Easy access object\n",
    "df_M = [ \"df_customers\", \"df_geolocation\", \"df_order_items\", \"df_payments\", \"df_reviews\", \"df_products\", \"df_sellers\", \"df_closed\", \"df_leads\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab76a5f0-f337-484c-9e02-9e7c2e76e81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Identify columns\n",
    "df_customers.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07981d0d-a231-4dca-895a-99740dbd0c1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seller_id</th>\n",
       "      <th>seller_zip_code_prefix</th>\n",
       "      <th>seller_city</th>\n",
       "      <th>seller_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3442f8959a84dea7ee197c632cb2df15</td>\n",
       "      <td>13023</td>\n",
       "      <td>campinas</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d1b65fc7debc3361ea86b5f14c68d2e2</td>\n",
       "      <td>13844</td>\n",
       "      <td>mogi guacu</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ce3ad9de960102d0677a81f5d0bb7b2d</td>\n",
       "      <td>20031</td>\n",
       "      <td>rio de janeiro</td>\n",
       "      <td>RJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c0f3eea2e14555b6faeea3dd58c1b1c3</td>\n",
       "      <td>4195</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51a04a8a6bdcb23deccc82b0b80742cf</td>\n",
       "      <td>12914</td>\n",
       "      <td>braganca paulista</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c240c4061717ac1806ae6ee72be3533b</td>\n",
       "      <td>20920</td>\n",
       "      <td>rio de janeiro</td>\n",
       "      <td>RJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>e49c26c3edfa46d227d5121a6b6e4d37</td>\n",
       "      <td>55325</td>\n",
       "      <td>brejao</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1b938a7ec6ac5061a66a3766e0e75f90</td>\n",
       "      <td>16304</td>\n",
       "      <td>penapolis</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>768a86e36ad6aae3d03ee3c6433d61df</td>\n",
       "      <td>1529</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ccc4bbb5f32a6ab2b7066a4130f114e3</td>\n",
       "      <td>80310</td>\n",
       "      <td>curitiba</td>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          seller_id  seller_zip_code_prefix  \\\n",
       "0  3442f8959a84dea7ee197c632cb2df15                   13023   \n",
       "1  d1b65fc7debc3361ea86b5f14c68d2e2                   13844   \n",
       "2  ce3ad9de960102d0677a81f5d0bb7b2d                   20031   \n",
       "3  c0f3eea2e14555b6faeea3dd58c1b1c3                    4195   \n",
       "4  51a04a8a6bdcb23deccc82b0b80742cf                   12914   \n",
       "5  c240c4061717ac1806ae6ee72be3533b                   20920   \n",
       "6  e49c26c3edfa46d227d5121a6b6e4d37                   55325   \n",
       "7  1b938a7ec6ac5061a66a3766e0e75f90                   16304   \n",
       "8  768a86e36ad6aae3d03ee3c6433d61df                    1529   \n",
       "9  ccc4bbb5f32a6ab2b7066a4130f114e3                   80310   \n",
       "\n",
       "         seller_city seller_state  \n",
       "0           campinas           SP  \n",
       "1         mogi guacu           SP  \n",
       "2     rio de janeiro           RJ  \n",
       "3          sao paulo           SP  \n",
       "4  braganca paulista           SP  \n",
       "5     rio de janeiro           RJ  \n",
       "6             brejao           PE  \n",
       "7          penapolis           SP  \n",
       "8          sao paulo           SP  \n",
       "9           curitiba           PR  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Small sample of table \n",
    "df_sellers[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ca00c9-545e-45ad-97c6-317804b51e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58522273-ab0e-491f-a1ad-3a381842e551",
   "metadata": {},
   "source": [
    "*Text columns were explored as follows*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2a228bbc-0212-477e-942e-1441199b47c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    SP\n",
       "1    SP\n",
       "2    SP\n",
       "3    SP\n",
       "4    SP\n",
       "5    SC\n",
       "6    SP\n",
       "7    MG\n",
       "8    PR\n",
       "9    MG\n",
       "Name: customer_state, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Fast review of data \n",
    "df_customers[\"customer_state\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fc2f120-8fc5-4a85-9ffd-63b4db946261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     99441\n",
       "unique       27\n",
       "top          SP\n",
       "freq      41746\n",
       "Name: customer_state, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Frequency summary for categories\n",
    "df_customers[\"customer_state\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c562b5c8-9915-4519-b071-37a510ee30d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Identification of unique values\n",
    "df_customers[\"customer_state\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847905f1-ffa6-45ab-8227-9b31fdcd79bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Nulls count per column\n",
    "df_customers[\"customer_state\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dd7758b-84a5-4f53-94d6-476fa0a78d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Identification of data type\n",
    "df_customers[\"customer_state\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca462981-73cf-4eaf-8ce6-bf9f68dd300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Identification of unexpected lenghts \n",
    "df_customers[df_customers[\"customer_id\"].str.len()!=32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb98332-b8db-485d-ac8c-2849687a70d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Values supposed to be unique are unique \n",
    "(df_closed[\"mql_id\"].value_counts() > 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd4050b-21e6-4a20-bb2c-2c2d272fe508",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For exploration of columns with big amount of cateogires \n",
    "for val in sorted(df_geolocation[\"geolocation_city\"].unique()):\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291d96aa-bf08-46e9-b262-586003fed6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ce8d3d2-0150-410b-9bd5-df6b19be56f1",
   "metadata": {},
   "source": [
    "*Numeric columns were explored as follows*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1df187-f81d-4de0-8505-94a147515ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fast review of data \n",
    "df_products[\"product_height_cm\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847e89d4-5a82-4e52-be9e-46e59000d3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Identification of data type\n",
    "df_products[\"product_height_cm\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a35c7e1-2ae7-489d-8095-06a81717b693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    32949.000000\n",
       "mean        16.937661\n",
       "std         13.637554\n",
       "min          2.000000\n",
       "25%          8.000000\n",
       "50%         13.000000\n",
       "75%         21.000000\n",
       "max        105.000000\n",
       "Name: product_height_cm, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Data distribution\n",
    "df_products[\"product_height_cm\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883788bb-1436-45aa-81d0-1b37c1056f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Nulls count per column\n",
    "df_order_items[\"product_height_cm\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3494dd77-4272-4460-9ca2-5efb2ec2d40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fast visualization of data distribution \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "sns.boxplot (y = df_products[\"product_height_cm\"] )\n",
    "plt.ylabel(\"Largo\")\n",
    "plt.title(\"Largo en centimetros\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04acfd80-09c2-49fe-8105-1ba50e5a99fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fast visualization of data distribution (showfliers = False)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "sns.boxplot (y = df_products[\"product_height_cm\"], showfliers = False )\n",
    "plt.ylabel(\"Largo\")\n",
    "plt.title(\"Largo en centimetros\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb5872a-bea8-4719-85a2-7b42eef41cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4535b0fb-dc59-4f99-b69d-23b001136e00",
   "metadata": {},
   "source": [
    "*Date columns were explored as follows*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c44e2a-c2cd-4087-837f-aba1d71d6f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fast review of data \n",
    "df_orders[\"order_purchase_timestamp\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7450f0-cb3e-4f57-a052-1d58bc81e352",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Identification of data type\n",
    "df_orders[\"order_purchase_timestamp\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57487c3e-9a19-48f8-9a6a-1dc4f6c47e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Nulls count per column\n",
    "df_orders[\"order_purchase_timestamp\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2882ed9-39f4-44fa-bee5-899cb236d7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c151484d-4637-4527-bf65-86571896a966",
   "metadata": {},
   "source": [
    "## **EDA Conclusions**\n",
    "\n",
    "### This was detected in data as relevant prior use as input for model and the selected correction.\n",
    "\n",
    "- Nulls distribution.\n",
    "- `df_geolocation[\"geolocation_city\"]` has duplicated categories due to small variations in writing (Not in model).\n",
    "- Date columns has wrong data type.\n",
    "- `df_products[\"product_category_name\"]` has duplicated categories due to small variations in writing.\n",
    "- `df_products[\"product_category_name\"]` has \"alimentos\", \"alimentos_bebidas\", \"bebidas\". Unclear overlap.    \n",
    "- `df_sellers[\"seller_city\"]` gas values that are likely an error (Not in model).\n",
    "\n",
    "### This are the conslusions for the data.\n",
    "\n",
    "- The nulls amount is relatively small, may be ereased  for esae cleniang without compromising analisis.\n",
    "- `df_geolocation[\"geolocation_city\"]` is not required in models son no cleaning process is taken.\n",
    "- `df_products[\"product_category_name\"]` has high granularity. Subcategories are not treated as issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e07f22-3052-4a44-996f-e99da8d96e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8275d105-f72f-4d5e-9a5f-5c84d72158b4",
   "metadata": {},
   "source": [
    "## **Model Testing Instrucctions**\n",
    "### The following is the full data preprocesing for the best model.\n",
    "For a fast result of final model just execute the cells indicated as follows.\n",
    "- Main step 1.\n",
    "- Main step 2.\n",
    "- Main step 3.\n",
    "  \n",
    "### Prior the finding of this, multiple data sets and models were tested. To try an specific model use parameters specified in `Results` secction and  do as follows.\n",
    "\n",
    "- Round 1 (R1) lacks column \"x[\"Days_Early\"]\", step #13 must be removed to reproduce  any R1 models. \n",
    "- For models LogReg_A_R1 and LogReg_B_R1  add step #19A.\n",
    "- For model RF_D_R1 add step #19B.\n",
    "- For models in round 2 (R2) the next cells are ready to execute, tuning cell can be ommited for RF_A_R2 but doesnt change model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31c0cb0-29b6-4c3d-9d0f-bccb2775b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###19A Scaled data for linnear model \n",
    "x_train_columns = x_train.columns.copy()\n",
    "x_train_Scaled = x_train.copy()\n",
    "x_test_Scaled = x_test.copy()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "cols = [\"freight_value\", \"payment_installments\", \"product_weight_g\" ]\n",
    "\n",
    "x_train_Scaled[cols] = scaler.fit_transform(x_train[cols])\n",
    "x_test_Scaled[cols] = scaler.transform(x_test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2abc3d-651e-4976-9940-815fa9448bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###19B Alternative x removing low importance variables\n",
    "x_trainB = x_train[[\"Days_TA\", \"price\", \"freight_value\", \"product_weight_g\", \"payment_installments\", \"customer_state_RJ\", \"payment_type_boleto\", \"product_category_name_moveis_decoracao\"]]\n",
    "x_testB = x_test[[\"Days_TA\", \"price\", \"freight_value\", \"product_weight_g\", \"payment_installments\", \"customer_state_RJ\", \"payment_type_boleto\", \"product_category_name_moveis_decoracao\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a014f18e-b8ea-474c-b55a-88f4e3f09c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "###13 x[\"Days_Early\"] column creation\n",
    "x[\"Days_Early\"] = ( x[\"order_estimated_delivery_date\"] -x[\"order_delivered_customer_date\"]  ).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bf9829-f893-4c8f-b908-7bf92bb746bb",
   "metadata": {},
   "source": [
    "**Main step 1** (cell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de5ec0c5-c8b5-4cb8-ad3f-86fd69c43673",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data preprocesing to add more FE\n",
    "\n",
    "##1 Data upload\n",
    "import pandas as pd\n",
    "\n",
    "ruta1 = r\"C:/Users/Azul/Documents/Datos/Brazilian/e-commerce/\"\n",
    "ruta2 = r\"C:/Users/Azul/Documents/Datos/Brazilian/Funel/\"\n",
    "\n",
    "df_customers = pd.read_csv(ruta1 + \"olist_customers_dataset.csv\")\n",
    "df_geolocation = pd.read_csv(ruta1 + \"olist_geolocation_dataset.csv\")\n",
    "df_order_items = pd.read_csv(ruta1 + \"olist_order_items_dataset.csv\")\n",
    "df_payments = pd.read_csv(ruta1 + \"olist_order_payments_dataset.csv\")\n",
    "df_reviews = pd.read_csv(ruta1 + \"olist_order_reviews_dataset.csv\")\n",
    "df_orders = pd.read_csv(ruta1 + \"olist_orders_dataset.csv\")\n",
    "df_products = pd.read_csv(ruta1 + \"olist_products_dataset.csv\")\n",
    "df_sellers = pd.read_csv(ruta1 + \"olist_sellers_dataset.csv\")\n",
    "df_category = pd.read_csv(ruta1 + \"product_category_name_translation.csv\")\n",
    "\n",
    "df_closed = pd.read_csv(ruta2 + \"olist_closed_deals_dataset.csv\")\n",
    "df_leads = pd.read_csv(ruta2 + \"olist_marketing_qualified_leads_dataset.csv\")\n",
    "\n",
    "#2 Table for reference\n",
    "df_Ma =  [\"df_order_items\", \"df_payments\", \"df_products\", \"df_customers\", \"df_orders\", \"df_reviews\"]\n",
    "\n",
    "#3 Data type correction in date columns\n",
    "import pandas as pd\n",
    "\n",
    "for x in df_Ma:\n",
    "    df = globals()[x]\n",
    "    for z in df.columns:\n",
    "        if z == \"order_purchase_timestamp\" or z == \"order_delivered_customer_date\" or z == \"order_estimated_delivery_date\":\n",
    "            df[z] = pd.to_datetime(df[z])\n",
    "\n",
    "#4 Preprocesing for df merge\n",
    "a = df_order_items[[ \"price\", \"freight_value\", \"order_id\", \"product_id\" ]]\n",
    "b = df_payments[[ \"payment_type\", \"payment_installments\", \"order_id\" ]]\n",
    "c = df_products[[ \"product_category_name\", \"product_weight_g\", \"product_id\" ]]\n",
    "d = df_customers[[\"customer_state\", \"customer_id\"]]\n",
    "e = df_orders[[\"order_purchase_timestamp\", \"order_delivered_customer_date\", \"customer_id\", \"order_id\", \"order_estimated_delivery_date\"]]\n",
    "f = df_reviews[[\"review_score\", \"order_id\"]]\n",
    "\n",
    "#5 df merge\n",
    "import pandas as pd\n",
    "\n",
    "TablaM = pd.merge( a, b, how = \"inner\", on = \"order_id\" )\n",
    "TablaM = pd.merge( TablaM, e, how = \"inner\", on = \"order_id\" )\n",
    "TablaM = pd.merge( TablaM, f, how = \"inner\", on = \"order_id\" )\n",
    "TablaM = pd.merge( TablaM, c, how = \"inner\", on = \"product_id\" )\n",
    "TablaM = pd.merge( TablaM, d, how = \"inner\", on = \"customer_id\" )\n",
    "\n",
    "#6 Nulls erasing\n",
    "TablaM = TablaM.dropna()\n",
    "\n",
    "#7 Convert review_score into binary target. 1 for scores < 4, 0 otherwise\n",
    "TablaM.loc[TablaM[\"review_score\"]<4, \"review_score\"] = 1\n",
    "TablaM.loc[TablaM[\"review_score\"]>=4, \"review_score\"] = 0\n",
    "\n",
    "#8 y creation\n",
    "y = TablaM[\"review_score\"]\n",
    "\n",
    "#9 x creation\n",
    "x = TablaM.drop(\"review_score\", axis = 1)\n",
    "\n",
    "#10 Duplicated categories converted \n",
    "x.loc[ x[\"product_category_name\"] == \"casa_conforto_2\" , \"product_category_name\"] = \"casa_conforto\"\n",
    "x.loc[ x[\"product_category_name\"] == \"eletrodomesticos_2\" , \"product_category_name\"] = \"eletrodomesticos\"\n",
    "\n",
    "#11 Categorical columns converted to dummies\n",
    "import pandas as pd\n",
    "cols = [\"payment_type\", \"product_category_name\", \"customer_state\"]\n",
    "x = pd.get_dummies(x, columns = cols )\n",
    "\n",
    "#12 x[\"Days_TA\"] column creation\n",
    "x[\"Days_TA\"] = (x[\"order_delivered_customer_date\"] - x[\"order_purchase_timestamp\"]).dt.days\n",
    "\n",
    "#13 x[\"Days_Early\"] column creation\n",
    "x[\"Days_Early\"] = ( x[\"order_estimated_delivery_date\"] -x[\"order_delivered_customer_date\"]  ).dt.days\n",
    "\n",
    "#14 Redundant and unnecesary columns ereased\n",
    "x = x.drop([\"order_delivered_customer_date\", \"order_purchase_timestamp\", \"order_estimated_delivery_date\"], axis = 1)\n",
    "\n",
    "#15 The most frequent categories are droped as they are considered base categories. \n",
    "x = x.drop([\"product_category_name_cama_mesa_banho\", \"customer_state_SP\", \"payment_type_credit_card\"], axis = 1)\n",
    "\n",
    "#16 id columns droped due to being unnecesary for model training\n",
    "import pandas as pd\n",
    "x = x.drop ([\"order_id\", \"product_id\", \"customer_id\"], axis = 1)\n",
    "\n",
    "#17 train and test varaibles creation \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= .2, random_state = 42, stratify = y )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c8376d-391f-4263-9790-64eaff370303",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Used to decide cols in x_trainB and x_testB\n",
    "### Only if step #13 was removed \n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(RF_B_R1, x_train, y_train, scoring='f1', n_repeats=5, random_state=42, n_jobs=-1)\n",
    "importances_df = pd.DataFrame({\n",
    "    'Feature': x_train.columns,\n",
    "    'Importance': result.importances_mean\n",
    "}).sort_values(by = \"Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd2fe8a-6f61-4008-a1e3-f3cac57bfacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RandomForestClassifier \"balanced\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF_A_R2 = RandomForestClassifier(class_weight = \"balanced\", random_state = 42)\n",
    "RF_A_R2.fit(x_train, y_train)\n",
    "y_pred = RF_A_R2.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))\n",
    "print(\"f1:\",f1_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a760f6-8f82-44b7-ad9e-cd465053eeb1",
   "metadata": {},
   "source": [
    "**Main step 2** (below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc068be7-ffc3-47cd-be0c-1919b33df0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "f1_score: 0.574284304047384\n",
      "accuracy_score: 0.8476619419790701\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8523    0.9697    0.9072     17397\n",
      "           1     0.8153    0.4432    0.5743      5250\n",
      "\n",
      "    accuracy                         0.8477     22647\n",
      "   macro avg     0.8338    0.7065    0.7408     22647\n",
      "weighted avg     0.8438    0.8477    0.8300     22647\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Basic Tuning for selected model \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "\n",
    "\n",
    "RF_B_R2 = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],        \n",
    "    'max_depth': [None, 10, 20],       \n",
    "    'min_samples_split': [2, 5],       \n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    RF_B_R2,\n",
    "    param_grid,\n",
    "    scoring='f1',  \n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "RF_B_R2 = grid.best_estimator_\n",
    "y_pred = RF_B_R2.predict(x_test)\n",
    "\n",
    "# Métricas\n",
    "print('f1_score:', f1_score(y_test, y_pred, average='binary'))\n",
    "print('accuracy_score:', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126d95f2-2dae-43b6-ab5d-cd211cef63b8",
   "metadata": {},
   "source": [
    "**Main step 3** (below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7577e30c-e268-4b2c-9ec5-252e7e0da6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>product_category_name_beleza_saude</td>\n",
       "      <td>0.046827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>customer_state_MG</td>\n",
       "      <td>0.047073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>payment_type_boleto</td>\n",
       "      <td>0.068712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>customer_state_RJ</td>\n",
       "      <td>0.077231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>payment_installments</td>\n",
       "      <td>0.256661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>product_weight_g</td>\n",
       "      <td>0.297740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>freight_value</td>\n",
       "      <td>0.300039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>price</td>\n",
       "      <td>0.337101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Days_TA</td>\n",
       "      <td>0.410922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Days_Early</td>\n",
       "      <td>0.415251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Feature  Importance\n",
       "18   product_category_name_beleza_saude    0.046827\n",
       "87                    customer_state_MG    0.047073\n",
       "4                   payment_type_boleto    0.068712\n",
       "95                    customer_state_RJ    0.077231\n",
       "2                  payment_installments    0.256661\n",
       "3                      product_weight_g    0.297740\n",
       "1                         freight_value    0.300039\n",
       "0                                 price    0.337101\n",
       "103                             Days_TA    0.410922\n",
       "104                          Days_Early    0.415251"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Used for interpretability in final model \n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(RF_B_R2, x_train, y_train, scoring='f1', n_repeats=5, random_state=42, n_jobs=-1)\n",
    "importances_df = pd.DataFrame({\n",
    "    'Feature': x_train.columns,\n",
    "    'Importance': result.importances_mean\n",
    "}).sort_values(by = \"Importance\")\n",
    "importances_df[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd4c2f-19ef-41af-a049-1792aee504d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffcb56e6-30ff-4ae2-a643-2b7713b7910e",
   "metadata": {},
   "source": [
    "## Results Presentation\n",
    "As told before, multiple models were tested. Below is a summary of results at `Metrics_df` that can be reproduced with descriptions from `Models_df`. Next secction is suggested to not be skipped, all cells must be executed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e913781c-7127-46c5-8e11-15f1e2c7c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "Models_df = pd.read_csv(\"../Results/Model_Definitions_and_Results.csv\")\n",
    "Metrics_df = pd.read_csv(\"../Results/Performance_Metrics_per_Model.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "90de777f-3e63-4808-a95b-8684ad6166d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>Model_Definition</th>\n",
       "      <th>Feature_Set</th>\n",
       "      <th>Round</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogReg_A_R1</td>\n",
       "      <td>LogisticRegression(max_iter=5000, random_state=42)</td>\n",
       "      <td>x_train_Scaled, x_test_Scaled</td>\n",
       "      <td>R1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg_B_R1</td>\n",
       "      <td>LogisticRegression(class_weight='balanced', max_iter=5000, random_state=42)</td>\n",
       "      <td>x_train_Scaled, x_test_Scaled</td>\n",
       "      <td>R1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF_A_R1</td>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "      <td>x_train, x_test</td>\n",
       "      <td>R1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF_B_R1</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced', random_state=42)</td>\n",
       "      <td>x_train, x_test</td>\n",
       "      <td>R1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGB_A_R1</td>\n",
       "      <td>XGBClassifier(random_state=42)</td>\n",
       "      <td>x_train, x_test</td>\n",
       "      <td>R1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGB_B_R1</td>\n",
       "      <td>XGBClassifier(random_state=42, scale_pos_weight=peso)</td>\n",
       "      <td>x_train, x_test</td>\n",
       "      <td>R1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RF_C_R1</td>\n",
       "      <td>RandomForestClassifier(random_state=42, class_weight='balanced') + GridSearch</td>\n",
       "      <td>x_train, x_test</td>\n",
       "      <td>R1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF_D_R1</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced', random_state=42)</td>\n",
       "      <td>x_trainB, x_testB (subset of features)</td>\n",
       "      <td>R1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RF_A_R2</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced', random_state=42)</td>\n",
       "      <td>x_train, x_test (with Days_Early)</td>\n",
       "      <td>R2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RF_B_R2</td>\n",
       "      <td>RandomForestClassifier(random_state=42, class_weight='balanced') + GridSearch</td>\n",
       "      <td>x_train, x_test (with Days_Early)</td>\n",
       "      <td>R2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model_Name  \\\n",
       "0  LogReg_A_R1   \n",
       "1  LogReg_B_R1   \n",
       "2      RF_A_R1   \n",
       "3      RF_B_R1   \n",
       "4     XGB_A_R1   \n",
       "5     XGB_B_R1   \n",
       "6      RF_C_R1   \n",
       "7      RF_D_R1   \n",
       "8      RF_A_R2   \n",
       "9      RF_B_R2   \n",
       "\n",
       "                                                                Model_Definition  \\\n",
       "0                             LogisticRegression(max_iter=5000, random_state=42)   \n",
       "1    LogisticRegression(class_weight='balanced', max_iter=5000, random_state=42)   \n",
       "2                                        RandomForestClassifier(random_state=42)   \n",
       "3               RandomForestClassifier(class_weight='balanced', random_state=42)   \n",
       "4                                                 XGBClassifier(random_state=42)   \n",
       "5                          XGBClassifier(random_state=42, scale_pos_weight=peso)   \n",
       "6  RandomForestClassifier(random_state=42, class_weight='balanced') + GridSearch   \n",
       "7               RandomForestClassifier(class_weight='balanced', random_state=42)   \n",
       "8               RandomForestClassifier(class_weight='balanced', random_state=42)   \n",
       "9  RandomForestClassifier(random_state=42, class_weight='balanced') + GridSearch   \n",
       "\n",
       "                              Feature_Set Round  \n",
       "0           x_train_Scaled, x_test_Scaled    R1  \n",
       "1           x_train_Scaled, x_test_Scaled    R1  \n",
       "2                         x_train, x_test    R1  \n",
       "3                         x_train, x_test    R1  \n",
       "4                         x_train, x_test    R1  \n",
       "5                         x_train, x_test    R1  \n",
       "6                         x_train, x_test    R1  \n",
       "7  x_trainB, x_testB (subset of features)    R1  \n",
       "8       x_train, x_test (with Days_Early)    R2  \n",
       "9       x_train, x_test (with Days_Early)    R2  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e07783ac-c218-4d82-84df-54b5885d9dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>Precision_Class_1</th>\n",
       "      <th>Recall_Class_1</th>\n",
       "      <th>F1_Class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogReg_A_R1</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>0.2430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg_B_R1</td>\n",
       "      <td>0.3484</td>\n",
       "      <td>0.5238</td>\n",
       "      <td>0.4185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF_A_R1</td>\n",
       "      <td>0.7838</td>\n",
       "      <td>0.4240</td>\n",
       "      <td>0.5503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF_B_R1</td>\n",
       "      <td>0.7860</td>\n",
       "      <td>0.4206</td>\n",
       "      <td>0.5480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGB_A_R1</td>\n",
       "      <td>0.7196</td>\n",
       "      <td>0.2269</td>\n",
       "      <td>0.3450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGB_B_R1</td>\n",
       "      <td>0.4143</td>\n",
       "      <td>0.5270</td>\n",
       "      <td>0.4640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RF_C_R1</td>\n",
       "      <td>0.7342</td>\n",
       "      <td>0.4503</td>\n",
       "      <td>0.5582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF_D_R1</td>\n",
       "      <td>0.7645</td>\n",
       "      <td>0.4316</td>\n",
       "      <td>0.5517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RF_A_R2</td>\n",
       "      <td>0.8485</td>\n",
       "      <td>0.4269</td>\n",
       "      <td>0.5680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RF_B_R2</td>\n",
       "      <td>0.8153</td>\n",
       "      <td>0.4432</td>\n",
       "      <td>0.5743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model_Name  Precision_Class_1  Recall_Class_1  F1_Class_1\n",
       "0  LogReg_A_R1             0.7456          0.1451      0.2430\n",
       "1  LogReg_B_R1             0.3484          0.5238      0.4185\n",
       "2      RF_A_R1             0.7838          0.4240      0.5503\n",
       "3      RF_B_R1             0.7860          0.4206      0.5480\n",
       "4     XGB_A_R1             0.7196          0.2269      0.3450\n",
       "5     XGB_B_R1             0.4143          0.5270      0.4640\n",
       "6      RF_C_R1             0.7342          0.4503      0.5582\n",
       "7      RF_D_R1             0.7645          0.4316      0.5517\n",
       "8      RF_A_R2             0.8485          0.4269      0.5680\n",
       "9      RF_B_R2             0.8153          0.4432      0.5743"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75360262-9e05-49bb-8255-24974baac7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47a0053f-2a21-4d61-8439-075a4e120c66",
   "metadata": {},
   "source": [
    "## Model Optimization By Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7dc509ac-344a-4a9c-b0f7-12fce782a5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42: f1:0.5865, recall:0.4954, precision:0.7185 \n",
      "0.43: f1:0.5861, recall:0.4878, precision:0.734 \n",
      "0.44: f1:0.5845, recall:0.4798, precision:0.7475 \n",
      "0.45: f1:0.5837, recall:0.4741, precision:0.7591 \n",
      "0.46: f1:0.5832, recall:0.4682, precision:0.773 \n",
      "0.47: f1:0.5806, recall:0.4611, precision:0.7837 \n",
      "0.48: f1:0.5792, recall:0.4562, precision:0.793 \n",
      "0.49: f1:0.5782, recall:0.4509, precision:0.8059 \n"
     ]
    }
   ],
   "source": [
    "### Proba variations testing with restrictions \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "proba = RF_B_R2.predict_proba(x_test)[:, 1]\n",
    "for z in np.arange(0.3, 0.6, 0.01):\n",
    "    y_pred_thresh = (proba >= z).astype(int)\n",
    "    precision = precision_score(y_test, y_pred_thresh)\n",
    "    recall = recall_score(y_test, y_pred_thresh)\n",
    "    if (precision >= .7) and (recall>=.45):\n",
    "        f1 = f1_score(y_test, y_pred_thresh)\n",
    "        print (f\"{z:.2f}: f1:{f1:.4f}, recall:{recall:.4f}, precision:{precision:.4f} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9177dd12-0f00-4879-9a38-9ef0d6594451",
   "metadata": {},
   "source": [
    "**`threshold = .49` is the optimized value for the `RF_B_R2` model** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920ebb6b-6452-4db8-a91e-3ab32c48c2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Best model saving\n",
    "import joblib\n",
    "joblib.dump(RF_B_R2, 'RF_B_R2_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff130e58-79fa-4aee-90bd-731c1df1780b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b61c635-ade6-4a47-b99f-123031d4de54",
   "metadata": {},
   "source": [
    "# Project Conclusions\n",
    "The most effective model to explain the scores was RF_B_R2, which corresponds to a RandomForestClassifier with balanced classes. It was found that a significant part of the explainability comes from the days taken for delivery, whether meeting expectations or exceeding them. A large majority of records show that it is common to make deliveries prior to the expected date, which may indicate an actual current strategy: promise delivery on a certain day and actually deliver earlier.\n",
    "\n",
    "This model and its permutation importance reveal this pattern. However, this model relies on features that include the actual delivery date, so it cannot be used for any predictive purposes unless those delivery-related features are removed prior to further analysis.\n",
    "\n",
    "From a different perspective, while the model accomplishes its function, in a more product-based analysis the columns for days till arrival and early arrival should also be removed. Even though they truly impact the customer experience, they do not provide meaningful insights into the product expectations themselves. For a product-based focus, more aggressive feature engineering could be considered by correlating product characteristics, but this is unnecessary for the scope of this project.\n",
    "\n",
    "The two added columns related to delivery timing—days till arrival and days early—may induce collinearity in linear models, but the expectation is that Random Forest handles this well.\n",
    "\n",
    "The main conclusion is not only that the business seems to actively use an early delivery policy, but also that this policy is actually working.\n",
    "That said, further analysis would be helpful since only 30% of reviews are considered positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11e40aa-a063-490f-b3dd-4478f487e507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
